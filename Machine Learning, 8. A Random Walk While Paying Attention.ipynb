{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = 'center'>Guessing Games</h1>\n",
    "<h3 align = 'center'>machine learning, one step at a time</h3>\n",
    "<h3 align = 'center'>Step 8. A Random Walk While Paying Attention</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. A random walk while paying attention.**\n",
    "\n",
    "When we took our random walk, we ignored everything that happened except for one event: stumbling accross the exit.\n",
    "\n",
    "What if we paid attention, and learned from our mistakes?\n",
    "\n",
    "Let's start thinking about the maze in terms of machine learning: _the art of accumulating knowledge by learning from mistakes_.\n",
    "\n",
    "We have already seen that, when we explore the maze, it gives us feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- walk number 0 -----------------------\n",
      "[0 1] 0 False\n",
      "[0 0] 0 False\n",
      "[ 0 -1] -1 True\n",
      "\n",
      "--- walk number 1 -----------------------\n",
      "[ 0 -1] -1 True\n",
      "\n",
      "--- walk number 2 -----------------------\n",
      "[1 0] 0 False\n",
      "[1 1] -1 True\n",
      "\n",
      "--- walk number 3 -----------------------\n",
      "[0 1] 0 False\n",
      "[0 0] 0 False\n",
      "[ 0 -1] -1 True\n",
      "\n",
      "--- walk number 4 -----------------------\n",
      "[1 0] 0 False\n",
      "[2 0] 0 False\n",
      "[ 2 -1] -1 True\n"
     ]
    }
   ],
   "source": [
    "from maze import Maze\n",
    "\n",
    "# take five random walks through the maze\n",
    "maze = Maze()\n",
    "for i in range(5):\n",
    "    maze.reset()      # go back to the initial state\n",
    "    done = False\n",
    "    print('\\n--- walk number ' + str(i) + ' -----------------------')\n",
    "    while not done:\n",
    "        state, reward, done = maze.step(maze.sample())\n",
    "        print(state, reward, done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to learn from those results, we would to remember our rewards or penalties. We would need to store something, someplace.\n",
    "\n",
    "What would we store? ...well, we only know one thing: the result of taking an __action__ when in a given __state__. For example, here is the result of moving north immediately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state = [0 0]\n",
      "new_state = [-1  0] reward = -1 done = True\n",
      "Moving North is a bad idea!...\n",
      "...I should make a note of that.\n"
     ]
    }
   ],
   "source": [
    "initial_state = maze.reset()\n",
    "new_state, reward, done = maze.step('N')\n",
    "\n",
    "print('initial state =', initial_state)\n",
    "print('new_state =', new_state, 'reward =', reward, 'done =', done)\n",
    "print('Moving North is a bad idea!...')\n",
    "print('...I should make a note of that.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so there's that.\n",
    "\n",
    "Seems like we should associate ( state(0,0) + action(N) = bad idea ).\n",
    "\n",
    "And looking forward, it seems like we should be able to remember the reward associated with any __current state__ and __subsequent action__ (this is called a __transition__, because the __action__ causes us to transit from one __state__ to another).\n",
    "\n",
    "We need a place to put all of our __rewards__ and __penalties__. How should we do that?\n",
    "\n",
    "The maze will reveal two things that will help us to discover the _dimensions_ of that part of the problem.\n",
    "\n",
    "One set of dimensions, that we have seen before, is the __action space__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'S', 'E', 'W']\n",
      "There are 4 possible actions\n"
     ]
    }
   ],
   "source": [
    "print(maze.action_space())\n",
    "print('There are',len(maze.action_space()),'possible actions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the other set of dimensions, which our maze also provides, is the __state space__:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the dimensions of all possible states: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Here are the dimensions of all possible states:',maze.state_space())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE TO THE CURIOUS: it's not strictly necessary that the maze provide the dimensions of the state space. We could discover that just by exploring the space over and over. It's provided here just to simplify the example._\n",
    "\n",
    "So we need to be able to remember the results of any of 4 actions taken in a 4x4 space, which makes: 4x4x4, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np     # this library does all kinds of magical things with numbers\n",
    "q = np.zeros((4,4,4))  # don't worry about these details, just go with it\n",
    "print(q)               # everyone calls this data structure 'q'... it probably stands for 'quality'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to remember that going north right away is a bad idea...\n",
    "\n",
    "Recall that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state  = [0 0]\n",
      "result = (array([-1,  0]), -1, True)\n"
     ]
    }
   ],
   "source": [
    "print('state  =', maze.reset())\n",
    "print('result =', maze.step('N'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means _when I was in state (0,0), and chose action 'N\", I got a reward of -1._\n",
    "\n",
    "Or, _the quality of the action 'N' from state (0,0) is, well, pretty bad._\n",
    "\n",
    "For convenience, let's convert our actions to numbers, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 0\n",
      "S 1\n",
      "E 2\n",
      "W 3\n"
     ]
    }
   ],
   "source": [
    "# Here is a helpful function that you may need...\n",
    "# it converts N,S,E,W to 0,1,2,3\n",
    "\n",
    "def index_of_action(action):\n",
    "    return maze.action_space().index(action)\n",
    "\n",
    "# let's see how that works\n",
    "for action in maze.action_space():\n",
    "    print(action, index_of_action(action))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And store our penalty from moving North like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "q[0][0][index_of_action('N')] = -1   # the dimensions are [state_row][state_col][action]\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can remember past resutls, we can enforce our one-and-only decision rule: _don't do bad things_.\n",
    "\n",
    "(or: select from among the moves that have the highest available reward, based on past experience)\n",
    "\n",
    "Recall the shape of the maze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to store the __rewards__ or __penalties__ from every possible initial move, we would get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.  0.  0. -1.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "# note that the row & col do not change...\n",
    "# these are the results of 4 transitions,\n",
    "# all starting from row = 0, col = 0.\n",
    "q[0][0][index_of_action('N')] = -1\n",
    "q[0][0][index_of_action('S')] = 0\n",
    "q[0][0][index_of_action('E')] = 0\n",
    "q[0][0][index_of_action('W')] = -1\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This q-table says 'hey, if you are just starting out... don't go north or west!'\n",
    "<hr>\n",
    "***Exercises***<p>\n",
    "    \n",
    "- Build a q-table that learns incrementally from 100,000 walks through the maze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maze import Maze\n",
    "maze = Maze()\n",
    "\n",
    "# this converts N,S,E,W to 0,1,2,3\n",
    "def index_of_action(action):\n",
    "    return maze.action_space().index(action)\n",
    "\n",
    "q = np.zeros((4,4,4))\n",
    "for n in range(100000):\n",
    "    state = maze.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        \n",
    "        ####################################################################\n",
    "        #                                                                  #\n",
    "        #  YOUR CODE HERE:                                                 #\n",
    "        #    - get a sample action from the maze                           #\n",
    "        #    - use the action to take a step; capture the return values    #\n",
    "        #    - update the q table by adding the reward to:                 #\n",
    "        #        > row = state[0]                                          #\n",
    "        #        > col = state[1]                                          #\n",
    "        #        > action = index_of_action(whatever action you took)      #\n",
    "        #        > q[row][col][action] += reward                           #\n",
    "        #     - and don't forget to update your state                      #\n",
    "        #                                                                  #\n",
    "        ####################################################################\n",
    "\n",
    "print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
