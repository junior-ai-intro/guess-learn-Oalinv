{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = 'center'>Guessing Games</h1>\n",
    "<h3 align = 'center'>machine learning, one step at a time</h3>\n",
    "<h3 align = 'center'>Step 15. Final Project</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tic-tac-toe environment allows different types of players to play against each other. For example, here is a game between a __PrettyGoodPlayer__ (a procedural algorithm) and a __HumanPlayer__ (you):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import *\n",
    "\n",
    "g = Game(PrettyGoodPlayer(), HumanPlayer())\n",
    "g.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a __RandomPlayer__ playing a __VeryGoodPlayer__ (run this a few times to see what happens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import *\n",
    "\n",
    "g = Game(RandomPlayer(), VeryGoodPlayer())\n",
    "g.play()\n",
    "g.replay()     # this will display the game, like an instant replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is our nemesis __MinimaxPlayer__ playing a __VeryGoodPlayer__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import *\n",
    "\n",
    "g = Game(MinimaxPlayer(), VeryGoodPlayer())\n",
    "g.play()\n",
    "g.replay()     # this will display the game, like an instant replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "***Final Project***\n",
    "\n",
    "Implement the class __QPlayer__ that can play against the __MinimaxPlayer__, __RandomPlayer__, __VeryGoodPlayer__, or __HumanPlayer__. A __QPlayer__ should learn from its mistakes, and improve as it goes along.\n",
    "\n",
    "To interact with the tic-tac-toe environment, your player will need to implement certain functions (in this case, the __step()__ function is divided into two pieces: __move()__ and __update()__, in order to easily accommodate the different types of players).\n",
    "\n",
    "Here is a structural example of a new class player called __MyPlayer__ that shows how to use __move()__ and __update()__ to interact with the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import *\n",
    "\n",
    "# Define a Python class to represent a new type of player;\n",
    "# Extend the base class BasePlayer, which tracks wins and losses\n",
    "# and supports framework for identifying X-player v. O-player.\n",
    "class MyPlayer(BasePlayer):\n",
    "    \n",
    "    # call the superclass __init__ function... that will reset the \n",
    "    # won/loss/tie counters and do any other housekeeping.\n",
    "    def __init__(self):\n",
    "        super().__init__()       \n",
    "    \n",
    "    # move() is called when it is this player's turn\n",
    "    def move(self, game, state):\n",
    "        print('move:', state)\n",
    "        return game.sample(legal=True)\n",
    "\n",
    "    # update() is called after a winning move, an illegal move,\n",
    "    # or an opponent's move... update() provides feedback that\n",
    "    # results from this player's most recent move().\n",
    "    def update(self, game, state, reward, done):\n",
    "        print('update:',state, reward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this a few times; note how and when update() is called.\n",
    "\n",
    "from tictactoe import *\n",
    "g = Game(MyPlayer(), MinimaxPlayer())\n",
    "g.play()\n",
    "g.replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tictactoe import *\n",
    "\n",
    "###################################################################################\n",
    "#                                                                                 #\n",
    "#  FINAL PROJECT -- Implement QPlayer                                             #\n",
    "#                                                                                 #\n",
    "###################################################################################\n",
    "\n",
    "class QPlayer(BasePlayer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ###########################################################################\n",
    "        #                                                                         #\n",
    "        #  Create a q-table as a member variable for the class QPlayer...         #\n",
    "        #  ...something like: self.q = np.zeros(...something...)                  #\n",
    "        #                                                                         #\n",
    "        ###########################################################################\n",
    "\n",
    "    def move(self, game, state):\n",
    "        self.state = state\n",
    "        ###########################################################################\n",
    "        #                                                                         #\n",
    "        #  Here is where the exploring & learning takes place...                  #\n",
    "        #  ...set a variable called self.action, then return its value.           #\n",
    "        #                                                                         #\n",
    "        ###########################################################################\n",
    "        return self.action\n",
    "        \n",
    "    # update q-table, referring only to state & reward\n",
    "    def update(self, game, state, reward, done):\n",
    "        ###########################################################################\n",
    "        #                                                                         #\n",
    "        # Here is where the q-table gets updated, based on the result of the      #\n",
    "        # prior move (or more specifically: self.state and self.action)           #\n",
    "        #                                                                         #\n",
    "        ###########################################################################\n",
    "        \n",
    "\n",
    "# try training against various players!\n",
    "g = Game(QPlayer(), MinimaxPlayer())\n",
    "for n in range(100):\n",
    "    g.play()\n",
    "    print(g.x_player)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
