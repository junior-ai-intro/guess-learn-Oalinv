{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = 'center'>Guessing Games</h1>\n",
    "<h3 align = 'center'>machine learning, one step at a time</h3>\n",
    "<h3 align = 'center'>Step 10. Q-learning</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Q-learning**\n",
    "\n",
    "<u>Wikipedia</u> says:\n",
    "\n",
    "_Q-learning is a reinforcement learning technique used in machine learning. The goal of Q-Learning is to learn a policy, which tells an agent what action to take under what circumstances. It does not require a model of the environment and can handle problems with stochastic transitions and rewards, without requiring adaptations._\n",
    "\n",
    "Translation: 'Q-learning is a way to figure out a maze on-the-fly, without knowing it's a maze, even if it's like a fun-house maze where somebody occasionally moves the walls around.' The word __stochastic__ means 'like a fun-house', or: at least partly random, in some way or other.\n",
    "\n",
    "The last lesson was good enough to find a path without failing, but it wasn't quite Q-learning:\n",
    "- it examines the maze in advance... if someone moved the walls around, it would fail completely\n",
    "- it doesn't really develop much of a __policy__, in the sense that it still takes a random path\n",
    "- it is good at exploiting __penalties__, but what about exploiting __rewards__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Find the reward in this q-table:***\n",
    "<pre>\n",
    " =====  =========================\n",
    " state           action\n",
    " =====  =========================\n",
    "            N     S     E     W\n",
    " (0,0)  [-903.    0.    0. -830.]\n",
    " (0,1)  [-253. -215.    0.    0.]\n",
    " (0,2)  [ -58.    0.  -64.    0.]\n",
    " (0,3)  [   0.    0.    0.    0.]\n",
    "\n",
    " (1,0)  [   0.    0. -236. -231.]\n",
    " (1,1)  [   0.    0.    0.    0.]\n",
    " (1,2)  [   0.  -11.    0.  -14.]\n",
    " (1,3)  [  -3.    0.   -2.    0.]\n",
    "\n",
    " (2,0)  [   0.  -62.    0.  -79.]\n",
    " (2,1)  [ -15.   -9.  -10.    0.]\n",
    " (2,2)  [   0.    0.    0.    0.]\n",
    " (2,3)  [   0.   <font color='blue'>+1.</font>   -1.   -3.]   <font color='blue'>< -- we found the exit! from (2,3) -> move S</font>\n",
    "\n",
    " (3,0)  [   0.    0.    0.    0.]\n",
    " (3,1)  [   0.    0.    0.    0.]\n",
    " (3,2)  [   0.    0.    0.    0.]\n",
    " (3,3)  [   0.    0.    0.    0.]\n",
    " </pre>\n",
    " ***in this table, it took 3,000 tries to find the exit once***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
